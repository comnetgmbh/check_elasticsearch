#!/usr/bin/python
# -*- encoding: utf-8; py-indent-offset: 4 -*-

# Copyright (C) 2017 comNET GmbH
#
# This file is part of check_elasticsearch.
#
# check_elasticsearch is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Foobar is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with check_elasticsearch.  If not, see <http://www.gnu.org/licenses/>.

# Changelog:
# 2017-05-31, comNET GmbH, Fabian Binder - Initial version
# 2017-10-20, comNET GmbH, Fabian Binder - Add averaging for all indices
# 2017-10-25, comNET GmbH, Fabian Binder - Add cluster health and node health
# 2017-11-10, comNET GmbH, Fabian Binder - Update for usage as agent plugin
# 2017-11-13, comNET GmbH, Fabian Binder - Edit for agent bakery
# 2018-05-09, Lassi Kojo Oy, Lassi Kojo - Add support for SSL, custom CA and Basic auth
# 2018-05-09, Lassi Kojo Oy, Lassi Kojo - Improve index date pattern handling

import re
import requests
import os, sys

DEFAULT_SETTINGS = {
    'proto':   'http',
    'host':    'localhost',
    'port':    9200,
    'modules': ['health', 'nodestats', 'stats'],
    'username': None,
    'password': None,
    'ca': None,
}

# Read config file

settings = DEFAULT_SETTINGS
cfg_path = os.path.join(os.getenv("MK_CONFDIR", "/etc/check_mk/"),
                        "elasticsearch.cfg")
dict_from_file = []
try:
    with open(cfg_path, 'r') as inf:
        dict_from_file = eval(inf.read())

    for item in dict_from_file:
        settings[item] = dict_from_file[item]
except:
    pass

modules = settings['modules']
proto = settings['proto']
host = settings['host']
port = str(settings['port'])
username = settings['username']
password = settings['password']
ca = settings['ca']

index_date_pattern = "((-\d{4}(.|-){1}\d{2}(.|-){1}\d{2})|(-\d{4}(.|-){1}\d{2}))$"
date_expr = re.compile(index_date_pattern)

# Build URL

health_fields = "/_cluster/health?local=true"
health_url = proto + '://' + host + ':' + port + health_fields

nodestats_fields = "/_nodes/_local/stats/process"
nodestats_url = proto + '://' + host + ':' + port + nodestats_fields

stats_fields = "/_stats/store,docs"
stats_url = proto + '://' + host + ':' + port + '/*-*' + stats_fields

# Retrieve data from host

os.environ['NO_PROXY'] = host

# ------ Receive cluster health status ------
if "health" in modules:
    if username and password:
        if ca:
            response = requests.get(health_url, verify=ca, auth=(username, password))
        else:
            response = requests.get(health_url, auth=(username, password))
    elif ca:
        response = requests.get(health_url, verify=ca)
    else:
        response = requests.get(health_url)
    elasticsearch_health_response = response.json()

    print "<<<elasticsearch_health>>>"
    for item in elasticsearch_health_response:
        print "%s;%s" % (item, elasticsearch_health_response[item])

# ------ Receive node stats ------

if "nodestats" in modules:
    if username and password:
        if ca:
            response = requests.get(nodestats_url, verify=ca, auth=(username, password))
        else:
            response = requests.get(nodestats_url, auth=(username, password))
    elif ca:
        response = requests.get(nodestats_url, verify=ca)
    else:
        response = requests.get(nodestats_url)
    elasticsearch_nodestats_response = response.json()

    print "<<<elasticsearch_nodestats>>>"
    for node in elasticsearch_nodestats_response["nodes"]:
        node = elasticsearch_nodestats_response["nodes"][node]
        node_name = node["name"]
        print "%s;timestamp;%s" % (node_name, node["process"]["timestamp"])
        print "%s;open_file_descriptors;%s" % (node_name, node["process"]["open_file_descriptors"])
        print "%s;max_file_descriptors;%s" % (node_name, node["process"]["max_file_descriptors"])
        print "%s;cpu_percent;%s" % (node_name, node["process"]["cpu"]["percent"])
        print "%s;cpu_total_in_millis;%s" % (node_name, node["process"]["cpu"]["total_in_millis"])
        print "%s;mem_total_virtual_in_bytes;%s" % (node_name, node["process"]["mem"]["total_virtual_in_bytes"])

# ------ Receive stats about shards, clusters and indices ------

if "stats" in modules:
    if username and password:
        if ca:
            response = requests.get(stats_url, verify=ca, auth=(username, password))
        else:
            response = requests.get(stats_url, auth=(username, password))
    elif ca:
        response = requests.get(stats_url, verify=ca)
    else:
        response = requests.get(stats_url)
    elasticsearch_stats_response = response.json()

    print "<<<elasticsearch_shards>>>"
    shards_total = elasticsearch_stats_response["_shards"]["total"]
    shards_success = elasticsearch_stats_response["_shards"]["successful"]
    shards_failed = elasticsearch_stats_response["_shards"]["failed"]
    print "%s;%s;%s" % (shards_total, shards_success, shards_failed)

    print "<<<elasticsearch_cluster>>>"
    if "docs" in elasticsearch_stats_response["_all"]["total"]:
        count = elasticsearch_stats_response["_all"]["total"]["docs"]["count"]
        size = elasticsearch_stats_response["_all"]["total"]["store"]["size_in_bytes"]
        print "%s;%s" % (count, size)

    print "<<<elasticsearch_indices>>>"
    indices = set()
    for i in elasticsearch_stats_response["indices"]:
        name = re.sub(date_expr, '', i)
        indices.add(name)
    for indice in list(indices):
        all_counts = []
        all_sizes = []
        for i in elasticsearch_stats_response["indices"]:
            name = re.sub(date_expr, '', i)
            if name == indice:
                all_counts.append(elasticsearch_stats_response["indices"][i]["total"]["docs"]["count"])
                all_sizes.append(elasticsearch_stats_response["indices"][i]["total"]["store"]["size_in_bytes"])
        print "%s;%s;%s" % (indice, sum(all_counts)/len(all_counts), sum(all_sizes)/len(all_sizes))
