#!/usr/bin/env python
# -*- encoding: utf-8; py-indent-offset: 4 -*-

# Copyright (C) 2017, 2018 comNET GmbH
#
# This file is part of check_elasticsearch.
#
# check_elasticsearch is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Foobar is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with check_elasticsearch.  If not, see <http://www.gnu.org/licenses/>.

# Changelog:
# 2017-05-31, comNET GmbH, Fabian Binder - Initial version
# 2017-10-20, comNET GmbH, Fabian Binder - Add averaging for all indices
# 2017-10-25, comNET GmbH, Fabian Binder - Add cluster health and node health
# 2017-11-13, comNET GmbH, Fabian Binder - Bugfix for elasticsearch not returning docs count
# 2018-03-27, comNET GmbH, Fabian Binder - Refactored
# 2018-05-09, Lassi Kojo Oy, Lassi Kojo - Add support for SSL, custom CA and Basic auth
# 2018-05-09, Lassi Kojo Oy, Lassi Kojo - Improve index date pattern handling

import re
import requests
import os, sys
import argparse

VERSION = '2018-03-27'

#############################################################################

parser = argparse.ArgumentParser(description='Check_MK elasticsearch Agent')
parser.add_argument('--proto', dest='proto', default = "http",
                    help='Use SSL secured connection (HTTPS)')
parser.add_argument('--ca', dest='ca', default = None,
                    help='Absolute path to custom CA certificate')
parser.add_argument('-u', '--username', dest='username', default = None,
                    help='Username for connecting to secured Elasticsearch instance')
parser.add_argument('--password', dest='password', default = None,
                    help='Password for connecting to secured Elasticsearch instance')
parser.add_argument('hosts', metavar='hosts', nargs = '+',
                    help='''Hostnames or IP addresses of the elasticsearch servers. If you
                            query an elasticsearch cluster, the first host that returns
                            elasticsearch data will be used.''')
parser.add_argument('-P', '--port', dest='port', default = "9200",
                    help='Use a non-standard port for connecting (standard is 9200)')
parser.add_argument('-p', '--piggyback', dest='piggyback', default = None,
                    help='Use this option to piggyback the agent output to another host')
parser.add_argument('-i', '--modules', dest='modules', default = "health,nodestats,stats",
                    help='''Comma-separated list of modules to query. Possible values:
                              health
                              nodestats
                              stats
                            By default, all available modules will be queried.''')
args = parser.parse_args()

# Prepare arguments

if args.modules:
    modules = args.modules.split(',')

# Output general information about the agent

sys.stdout.write('<<<check_mk>>>\n')
sys.stdout.write('Version: %s\n' % VERSION)
sys.stdout.write('AgentOS: linux\n')

import time
sys.stdout.write('<<<systemtime>>>\n')
sys.stdout.write(time.strftime('%s\n'))

# Build URL

for host in args.hosts:

    proto = args.proto
    port = args.port
    username = args.username
    password = args.password
    ca = args.ca

    index_date_pattern = "((-\d{4}(.|-){1}\d{2}(.|-){1}\d{2})|(-\d{4}(.|-){1}\d{2}))$"
    date_expr = re.compile(index_date_pattern)

    health_fields = "/_cluster/health?local=true"
    health_url = proto + '://' + host + ':' + port + health_fields

    nodestats_fields = "/_nodes/_local/stats/process"
    nodestats_url = proto + '://' + host + ':' + port + nodestats_fields

    stats_fields = "/_stats/store,docs"
    stats_url = proto + '://' + host + ':' + port + '/*-*' + stats_fields

    # Retrieve data from host

    os.environ['NO_PROXY'] = host

    try:
        # ------ Piggyback option ------

        if args.piggyback:
            print "<<<<%s>>>>" % args.piggyback

        # ------ Receive cluster health status ------

        if "health" in modules:
            if username and password:
                if ca:
                    response = requests.get(health_url, verify=ca, auth=(username, password))
                else:
                    response = requests.get(health_url, auth=(username, password))
            elif ca:
                response = requests.get(health_url, verify=ca)
            else:
                response = requests.get(health_url)
            elasticsearch_health_response = response.json()

            print "<<<elasticsearch_health:sep(59)>>>"
            for item in elasticsearch_health_response:
                print "%s;%s" % (item, elasticsearch_health_response[item])

        # ------ Receive node stats ------

        if "nodestats" in modules:
            if username and password:
                if ca:
                    response = requests.get(nodestats_url, verify=ca, auth=(username, password))
                else:
                    response = requests.get(nodestats_url, auth=(username, password))
            elif ca:
                response = requests.get(nodestats_url, verify=ca)
            else:
                response = requests.get(nodestats_url)
            elasticsearch_nodestats_response = response.json()

            print "<<<elasticsearch_nodestats:sep(59)>>>"
            for node in elasticsearch_nodestats_response["nodes"]:
                node = elasticsearch_nodestats_response["nodes"][node]
                node_name = node["name"]
                print "%s;timestamp;%s" % (node_name, node["process"]["timestamp"])
                print "%s;open_file_descriptors;%s" % (node_name, node["process"]["open_file_descriptors"])
                print "%s;max_file_descriptors;%s" % (node_name, node["process"]["max_file_descriptors"])
                print "%s;cpu_percent;%s" % (node_name, node["process"]["cpu"]["percent"])
                print "%s;cpu_total_in_millis;%s" % (node_name, node["process"]["cpu"]["total_in_millis"])
                print "%s;mem_total_virtual_in_bytes;%s" % (node_name, node["process"]["mem"]["total_virtual_in_bytes"])

        # ------ Receive stats about shards, clusters and indices ------

        if "stats" in modules:
            if username and password:
                if ca:
                    response = requests.get(stats_url, verify=ca, auth=(username, password))
                else:
                    response = requests.get(stats_url, auth=(username, password))
            elif ca:
                response = requests.get(stats_url, verify=ca)
            else:
                response = requests.get(stats_url)
            elasticsearch_stats_response = response.json()

            print "<<<elasticsearch_shards:sep(59)>>>"
            shards = elasticsearch_stats_response["_shards"]
            print "%s;%s;%s" % (shards["total"], shards["successful"], shards["failed"])

            print "<<<elasticsearch_cluster:sep(59)>>>"
            if "docs" in elasticsearch_stats_response["_all"]["total"]:
                count = elasticsearch_stats_response["_all"]["total"]["docs"]["count"]
                size = elasticsearch_stats_response["_all"]["total"]["store"]["size_in_bytes"]
                print "%s;%s" % (count, size)

            print "<<<elasticsearch_indices:sep(59)>>>"
            indices = set()
            for i in elasticsearch_stats_response["indices"]:
                name = re.sub(date_expr, '', i)
                indices.add(name)
            for indice in list(indices):
                all_counts = []
                all_sizes = []
                for i in elasticsearch_stats_response["indices"]:
                    name = re.sub(date_expr, '', i)
                    if name == indice:
                        all_counts.append(elasticsearch_stats_response["indices"][i]["total"]["docs"]["count"])
                        all_sizes.append(elasticsearch_stats_response["indices"][i]["total"]["store"]["size_in_bytes"])
                print "%s;%s;%s" % (indice, sum(all_counts)/len(all_counts), sum(all_sizes)/len(all_sizes))

        # ------ Piggyback option ------

        if args.piggyback:
            print "<<<<>>>>"

        # Exit if one of the cluster hosts returns data
        exit(0)

    # Try next cluster host if no data
    except Exception, e:
        pass
